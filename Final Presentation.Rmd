---
title: "The relationship between a song's audio features and popularity"
author: "Connor King"
date: "2023-05-23"
output:
  ioslides_presentation:
    widescreen: true
    incremental: false
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include = FALSE}
library(tidyverse)
library(corrplot)
library(ggpubr)
library(jmv)
```

```{r, include = FALSE}

df <- read_csv("C:/Users/13393/Documents/School/Senior yr/Stat 697MV/Final Project/Spotify_Youtube.csv")

df <- as_tibble(df)

dependent_columns <- c(6,8:18, 22:24, 28)

df1 <- df[, dependent_columns]
```


# Dataset

---

- The dataset is a combination of data from Spotify and Youtube and consists of several attributes.

- The Spotify data includes various characteristics of songs, like `Danceability`, `Energy`, `Key`, `Loudness`, `Speechiness`, `Acousticness`, `Instrumentalness`, `Liveness`, `Valence`, `Tempo`, and `Duration_ms`.

- The Youtube data, on the other hand, consists of dependent variables that measure the popularity of these songs on Youtube where the number of `Views`, `Likes`, `Comments` are tracked for the corresponding music video.

- The dependent variable of `Stream` was from Spotify which represents the number of times a particular song or track has been played or listened to on Spotify.

--- 

- `Album_type`: the album in which the song is contained on Spotify. (album, single, compilation)
- `Danceability`: describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity. 
- `Energy`: is a measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity.
- `Key`: the key the track is in. Integers map to pitches using standard Pitch Class notation.
- `Loudness`: the overall loudness of a track in decibels (dB). Loudness values are averaged across the entire track and are useful for comparing relative loudness of tracks. 
- `Speechiness`: detects the presence of spoken words in a track. The more exclusively speech-like the recording (e.g. talk show, audio book, poetry), the closer to 1.0 the attribute value. 

---
- `Acousticness`: a confidence measure from 0.0 to 1.0 of whether the track is acoustic. 1.0 represents high confidence the track is acoustic.
- `Instrumentallness`: predicts whether a track contains no vocals. The closer the instrumentalness value is to 1.0, the greater likelihood the track contains no vocal content.
- `Liveness`: detects the presence of an audience in the recording. Higher liveness values represent an increased probability that the track was performed live.
- `Valence`: racks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).
- `Tempo`: the overall estimated tempo of a track in beats per minute (BPM).
- `Duration_ms`: the duration of the track in milliseconds.

## Popularity/Dependent Variables

- `Stream`: the number of streams of the song on Spotify.
- `Likes`: the number of likes of the song's corresponding music video on YouTube
- `Views`: the number of views of the YouTube video
- `Comments`: the number of comments for the YouTube video

## Questions

In this project we sought to answer the following questions with multivariate analysis:

1. Can we predict the popularity of a song with the help of Spotify audio features?
  - Multiple Multivariate Regression
  - Bootstrap Study

2. How do characteristics of a song correlate with one another?
  - Correlation Plot
  - Principal Component Analysis / Factor Analysis
  
3. Are the differences in the means of the popularity variables between the `Album_type`'s? (album, compilation, single)
  - MANOVA

# Exploratory Analysis

## Summary

```{r grid1, echo = FALSE, out.width = "60%"}
knitr::include_graphics("summary.png")
```

## NA Values

```{r}
sapply(df1, function(x) mean(is.na(x)) * 100)
```

```{r, include = FALSE}
df1 <- na.omit(df1)
```

## Popularity/Dependent Variables

```{r, echo = FALSE}
par(mfrow = c(2, 2))

hist(df1$Views, main = "Distribution of Views", xlab = "Number of Views", col = "skyblue")
hist(df1$Comments, main = "Distribution of Comments", xlab = "Number of Comments",col = "skyblue")
hist(df1$Likes, main = "Distribution of Likes", xlab = "Number of Likes",col = "skyblue")
hist(df1$Stream, main = "Distribution of Streams", xlab = "Number of Streams",col = "skyblue")
```

## Popularity Boxplots

```{r, echo = FALSE}
par(mfrow = c(2, 2))

boxplot(df1$Views, main = "Distribution of Views", xlab = "Number of Views", col = "skyblue")
boxplot(df1$Comments, main = "Distribution of Comments", xlab = "Number of Comments",col = "skyblue")
boxplot(df1$Likes, main = "Distribution of Likes", xlab = "Number of Likes",col = "skyblue")
boxplot(df1$Stream, main = "Distribution of Streams", xlab = "Number of Streams",col = "skyblue")
```

## Omitting Outliers

```{r, echo = FALSE}
df1_dep <- df1[, 13:16]

df1_clean <- df1

for (col in colnames(df1_dep)) {
  Q1 <- quantile(df1_clean[[col]], 0.25, na.rm = TRUE)
  Q3 <- quantile(df1_clean[[col]], 0.75, na.rm = TRUE)
  IQR <- Q3 - Q1

  outliers <- df1_clean[[col]] < (Q1 - 1.5 * IQR) | df1_clean[[col]] > (Q3 + 1.5 * IQR)

  df1_clean <- df1_clean[!outliers, ]
}


par(mfrow = c(2, 2))

hist(df1_clean$Views, xlab = "Number of Views", col = "skyblue")
hist(df1_clean$Comments, xlab = "Number of Comments",col = "skyblue")
hist(df1_clean$Likes, xlab = "Number of Likes",col = "skyblue")
hist(df1_clean$Stream, xlab = "Number of Streams",col = "skyblue")
```

## Boxplots without outliers

```{r, echo = FALSE}
par(mfrow = c(2, 2))

boxplot(df1_clean$Views, xlab = "Number of Views", col = "skyblue")
boxplot(df1_clean$Comments, xlab = "Number of Comments",col = "skyblue")
boxplot(df1_clean$Likes, xlab = "Number of Likes",col = "skyblue")
boxplot(df1_clean$Stream, xlab = "Number of Streams",col = "skyblue")
```

## Log Transformation

```{r, echo = FALSE}
df1_dep <- df1[, 13:16]

df1_log <- log(df1[, 13:16])

par(mfrow = c(2, 2))

hist(df1_log$Views, xlab = "Number of Views", col = "skyblue")
hist(df1_log$Comments, xlab = "Number of Comments",col = "skyblue")
hist(df1_log$Likes, xlab = "Number of Likes",col = "skyblue")
hist(df1_log$Stream, xlab = "Number of Streams",col = "skyblue")
```

## Log Transformed Boxplots

```{r, echo = FALSE, warning=FALSE}
par(mfrow = c(2, 2))

boxplot(df1_log$Views, xlab = "Number of Views", col = "skyblue")
boxplot(df1_log$Comments, xlab = "Number of Comments",col = "skyblue")
boxplot(df1_log$Likes, xlab = "Number of Likes",col = "skyblue")
boxplot(df1_log$Stream, xlab = "Number of Streams",col = "skyblue")
```

## Song Metrics

```{r, echo=FALSE}
df1 %>%
  select(2:12) %>%
  pivot_longer(everything()) %>%
  ggplot(aes(x = value)) +
  geom_histogram(bins = 30, color = "black", fill = "skyblue") +
  facet_wrap(~name, scales = "free")
```

## Correlation Plot

```{r, echo=FALSE}
corr_plot_data <- df1 %>% select(Danceability, Energy, Key, Loudness, Speechiness, Acousticness,
                 Instrumentalness, Liveness, Valence, Tempo, Duration_ms)

corrplot(cor(corr_plot_data), 
         method = "color",  
         type = "upper", 
         order = "hclust")
```

# Multiple Multivariate Regression

## Regression

```{r}
n <- nrow(df1)

Y <- as.matrix(df1 %>% select(Views, Likes, Comments, Stream))
n <- nrow(Y)
m <- ncol(Y)
Z <- as.matrix(cbind(const = 1, df1 %>% select(2:12)))
r <- ncol(Z) - 1

b <- solve(t(Z) %*% Z) %*% t(Z) %*% Y   # LS estimators

```

## Least Squares Estimates 

```{r}
b
```

## R-squared 

```{r}
pred <- Z %*% b #matrix of predicted values
resid <- Y - pred #matrix of residuals

SSR <- diag(t(resid) %*% resid) # sum of squared residuals for each model
SST <- apply(Y, 2, function(y) sum((y - mean(y))^2)) # total sum of squares for each model
Rsq <- 1 - SSR / SST # R-squared for each model

print(Rsq)
```

## Diagnostic Checks

- Since our multivariate multiple regression model has been fit to the data, we must perform diagnostic checks for the single-response model.
- We will examine the residual vectors $[\hat{\epsilon}_{j1}, \hat{\epsilon}_{j2}, \hat{\epsilon}_{j3}, \hat{\epsilon}_{j4}]$ for normality or outliers.

```{r, include=FALSE}
#We need to reshape the data 

pred <- Z %*% b #matrix of predicted values
resid <- Y - pred #matrix of residuals

df_resid <- as.data.frame(resid)
df_pred <- as.data.frame(pred)

#Adding an observation number for each frame
df_resid$Obs <- 1:nrow(df_resid)
df_pred$Obs <- 1:nrow(df_pred)

#Reshaping from wide to long format
df_resid_long <- df_resid %>% pivot_longer(-Obs, names_to = "Dependent", values_to = "Residual")
df_pred_long <- df_pred %>% pivot_longer(-Obs, names_to = "Dependent", values_to = "Prediction")

df_long <- inner_join(df_pred_long, df_resid_long, by = c("Obs", "Dependent"))
```


## Residual Plots

```{r, echo = FALSE}
ggplot(df_long, aes(x = Prediction, y = Residual)) +
  geom_point(alpha = 0.2, color = "blue") +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  facet_wrap(~Dependent, scales = "free")
```

## Log Transformation

- The residual plot was biased, heteroscedastic and had far more positive residuals than negative.
- As we saw in our exploratory data analysis, it may be necessary to consider transformations. We will log-transform **Duration_ms** and **Instrumentalness** and then transform the popularity variables.

```{r, include = FALSE}
df1_log <- df1

#Adding constant to avoid taking log of 0
df1_log$Duration_ms <- log(df1_log$Duration_ms + 1)
df1_log$Instrumentalness <- log(df1_log$Instrumentalness + 1)
Y_log <- log(Y+1)

Z_log <- as.matrix(cbind(const = 1, df1_log %>% select(2:12)))

b_log <- solve(t(Z_log) %*% Z_log) %*% t(Z_log) %*% Y_log
pred_log <- Z_log %*% b_log
resid_log <- Y_log - pred_log

df_resid_log <- as.data.frame(resid_log)
df_pred_log <- as.data.frame(pred_log)

#Adding an observation number for each frame
df_resid_log$Obs <- 1:nrow(df_resid_log)
df_pred_log$Obs <- 1:nrow(df_pred_log)

#Reshaping from wide to long format
df_resid_long_log <- df_resid_log %>% pivot_longer(-Obs, names_to = "Dependent", values_to = "Residual")
df_pred_long_log <- df_pred_log %>% pivot_longer(-Obs, names_to = "Dependent", values_to = "Prediction")

df_long_log <- inner_join(df_pred_long_log, df_resid_long_log, by = c("Obs", "Dependent"))

```

## Log-Transformed Residual Plots

```{r, echo=FALSE}
ggplot(df_long_log, aes(x = Prediction, y = Residual)) +
  geom_point(alpha = 0.2, color = "blue") +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  facet_wrap(~Dependent, scales = "free")
```

## QQ Plots for Normality

```{r, echo=FALSE, warning=FALSE}
qq_plot <- function(df, dep_var) {
  df_filtered <- df[df$Dependent == dep_var,]
  ggqqplot(df_filtered, "Residual") +
    labs(title = dep_var, y = "Theoretical Quantiles")
}

# Apply the function to each dependent variable and store the results in a list
qq_plots <- lapply(unique(df_long_log$Dependent), qq_plot, df = df_long_log)

# Arrange the plots in a grid
qq_plots_grid <- ggarrange(plotlist = qq_plots)

print(qq_plots_grid)
```

## Log Model R-squared

```{r}
SSR <- diag(t(resid_log) %*% resid_log) # sum of squared residuals for each model
SST <- apply(Y_log, 2, function(y) sum((y - mean(y))^2)) # total sum of squares for each model
Rsq <- 1 - SSR / SST # R-squared for each model

print(Rsq)
```

## Bootstrap

```{r, include = FALSE}
S <- 10 #num samples

bootstrap_Rsq <- matrix(nrow = S, ncol = ncol(Y_log))

for (s in 1:S){
  bootstrap_sample_idx <- sample(nrow(df1_log), replace = TRUE)
  
  bstp_df <- df1_log[bootstrap_sample_idx, ]
  Y_bstp <- Y_log[bootstrap_sample_idx, , drop = FALSE]
  
  #fitting model on the bootstrap samples
  Z_bstp <- as.matrix(cbind(const = 1, bstp_df %>% select(2:12)))
  b_bstp <- solve(t(Z_bstp) %*% Z_bstp) %*% t(Z_bstp) %*% Y_bstp
  pred_bstp <- Z_bstp %*% b_bstp
  resid_bstp <- Y_bstp - pred_bstp
  
  #bootstrap Rsq
  SSR_bstp <- diag(t(resid_bstp) %*% resid_bstp)
  SST_bstp <- apply(Y_bstp, 2, function(y) sum((y-mean(y))^2))
  Rsq_bstp <- 1 - SSR_bstp / SST_bstp
  
  #storing bootstrap Rsq values
  bootstrap_Rsq[s, ] <- Rsq_bstp

}

CI_Rsq_bstp <- apply(bootstrap_Rsq, 2, function(rsq) quantile(rsq, probs = c(0.025, 0.975)))
```

```{r, echo = FALSE}
knitr::include_graphics("bootstrap_code.png")
```

## Bootstrapped R-sq Confidence Intervals

```{r}
print(CI_Rsq_bstp)
```

## Bootstrap Plots

```{r, echo=FALSE}
cols <- colnames(Y_log)

par(mfrow= c(2,2))

for (i in seq_along(cols)){
  hist(bootstrap_Rsq[, i],
    main = paste("Bootstrap R-square for", cols[i]),
    xlab = "R-squared",
    col = "skyblue")
               
}
```

## Regression Analysis

```{r}
b_log
```

## Variable Omission

From the analysis above, we will conduct a likelihood ratio test for regression parameters to see if a subset of the predictors has a statistically significant linear relationship to the outcome.

The variables `Key` and `Tempo` have very small coefficients for all popularity variables suggesting that their contributions may be negligible. 

$H_0: \beta_{Key} = \beta_{Tempo} = 0$

##

```{r, include = FALSE}
#testing whether or not the coefficients are all zero
variables_to_test <- c("Key", "Tempo")
variables_to_keep <- setdiff(colnames(Z_log), variables_to_test)

q <- length(variables_to_keep) - 1 
grp1 <- rownames(b_log) %in% variables_to_keep
grp2 <- rownames(b_log) %in% variables_to_test

estSigma <- t(resid_log) %*% resid_log / n

b_grp1 <- solve(t(Z_log[ , grp1]) %*% Z[ , grp1]) %*% t(Z_log[ , grp1]) %*% Y_log
pred_grp1 <- Z_log[ , grp1] %*% b_grp1
resid_grp1 <- Y_log - pred_grp1

estSigma1 <- t(resid_grp1) %*% resid_grp1/n

#Likelihood ratio test statistic and it's approx
LR_test_statistic <- -n * (log(det(estSigma)) - log(det(estSigma1)))

approx_LR_test_statistic <- -(n - r - 1 - 0.5 * (m - r + q + 1)) * (log(det(estSigma)) - log(det(estSigma1)))
```

```{r, echo = FALSE, out.width= "55%"}
knitr::include_graphics("key_tempo.png")
```


## Test Results

```{r}
ifelse(approx_LR_test_statistic > qchisq(0.95, m *(r-q)), "Reject H0", "Don't reject H0")

# The corresponding p-value is:
pchisq(approx_LR_test_statistic, df = m * (r - q), lower.tail = FALSE)
```

We rejected $H_0$ which means that we cannot drop all of `Key` and `Tempo`. The result indicates that at least one of the coefficients for these variables is significantly different from zero. 

## Omitting `Key`

```{r, include = FALSE}
#testing whether or not the coefficients are all zero
variables_to_test <- c("Key")
variables_to_keep <- setdiff(colnames(Z_log), variables_to_test)

q <- length(variables_to_keep) - 1 
grp1 <- rownames(b_log) %in% variables_to_keep
grp2 <- rownames(b_log) %in% variables_to_test

estSigma <- t(resid_log) %*% resid_log / n

b_grp1 <- solve(t(Z_log[ , grp1]) %*% Z_log[ , grp1]) %*% t(Z_log[ , grp1]) %*% Y_log
pred_grp1 <- Z_log[ , grp1] %*% b_grp1
resid_grp1 <- Y_log - pred_grp1

estSigma1 <- t(resid_grp1) %*% resid_grp1/n

#Likelihood ratio test statistic and it's approx
LR_test_statistic <- -n * (log(det(estSigma)) - log(det(estSigma1)))

approx_LR_test_statistic <- -(n - r - 1 - 0.5 * (m - r + q + 1)) * (log(det(estSigma)) - log(det(estSigma1)))
```

```{r, echo = FALSE, out.width= "55%"}
knitr::include_graphics("key.png")
```


## Results

```{r}
ifelse(approx_LR_test_statistic > qchisq(0.95, m *(r-q)), "Reject H0", "Don't reject H0")

pchisq(approx_LR_test_statistic, df = m * (r - q), lower.tail = FALSE)
```

$H_0: \beta_{Key} = 0

Since we rejected $H_0$ at the $\alpha = 0.05$ level, we cannot drop `Key`.

## Omitting `Tempo`

```{r, include =FALSE}
#testing whether or not the coefficients are all zero
variables_to_test <- c("Tempo")
variables_to_keep <- setdiff(colnames(Z_log), variables_to_test)

q <- length(variables_to_keep) - 1 
grp1 <- rownames(b_log) %in% variables_to_keep
grp2 <- rownames(b_log) %in% variables_to_test

estSigma <- t(resid_log) %*% resid_log / n

b_grp1 <- solve(t(Z_log[ , grp1]) %*% Z_log[ , grp1]) %*% t(Z_log[ , grp1]) %*% Y_log
pred_grp1 <- Z_log[ , grp1] %*% b_grp1
resid_grp1 <- Y_log - pred_grp1

estSigma1 <- t(resid_grp1) %*% resid_grp1/n

#Likelihood ratio test statistic and it's approx
LR_test_statistic <- -n * (log(det(estSigma)) - log(det(estSigma1)))

approx_LR_test_statistic <- -(n - r - 1 - 0.5 * (m - r + q + 1)) * (log(det(estSigma)) - log(det(estSigma1)))
```

```{r}
ifelse(approx_LR_test_statistic > qchisq(0.95, m *(r-q)), "Reject H0", "Don't reject H0")

pchisq(approx_LR_test_statistic, df = m * (r - q), lower.tail = FALSE)
```

We reject $H_0: \beta_{Tempo} = 0$

## Omission Analysis

The test results indicated that `Key` and `Tempo`do have a significant linear relationship with the outcomes. 

Since we are using the log-transformed model, the magnitude of a coefficient doesn't directly correspond to the magnitude of its effect on the outcome. Instead, each coefficient represents the average percentage change in the outcome for each one-unit increase in the corresponding predictor, all else being equal.

## Regression Conclusion:

**Model Performace**:  Despite performing transformations to improve the fit of our models, the R-squared values were low for both non-transformed and log-transformed models, suggesting our model does not explain a high amount of variance in the data. There is a large amount of unexplained variance, suggesting further improvements or additions are needed in our model.

**Feature Importance**: *Danceability*, *Loudness*, and *Duration_ms* seemed to have a positive association with song popularity across all metrics (Views, Likes, Comments, Stream). *Energy*, *Speechiness*, *Acousticness*, *Instrumentalness*, *Liveness*, and *Valence* were negatively associated with song popularity across all metrics.

**Omission**: *Key* and *Tempo*, despite having smaller coefficients, could not be omitted from the model as they showed a statistically significant linear relationship with the outcome variables.

**Improvements**: Given the model performance, future research could look into the interaction effects between variables or other non-linear relationships. Additional variables not considered in this study may also contribute to song popularity.

# One-Way MANOVA

## Album Type

- The variable `Album_types` (given by Spotify) within our dataset has the values "album", "compilation", and "single".

```{r}
df1_means <- df1 %>%
  group_by(Album_type) %>%
  summarise(across(c("Stream", "Views", "Likes", "Comments"), mean))

print(df1_means)
```

## Visualizations

```{r, include = FALSE}
agg_formula <- as.formula(paste("cbind(Likes, Views, Comments, Stream) ~ Album_type"))

# Calculate the means for each level of the factor
df1_group_means <- df1 %>%
  group_by(Album_type) %>%
  summarise(across(c("Stream", "Views", "Likes", "Comments"), mean))

df1_group_std <- df1 %>%
  group_by(Album_type) %>%
  summarise(across(c("Stream", "Views", "Likes", "Comments"), sd))



long_means <- df1_group_means %>%
  pivot_longer(cols = c("Likes", "Views", "Comments", "Stream"),
               names_to = "Variable",
               values_to = "Mean")

long_means <- long_means %>%
  group_by(Variable) %>%
  mutate(ScaledMean = scale(Mean))
```

```{r, echo = FALSE}
ggplot(long_means, aes(x = Album_type, y = Mean, fill = Album_type)) +
  geom_bar(stat = "Identity") +
  facet_wrap(~Variable, scales = "free") +
  labs(x = "Album Type", y = "Mean Value") 
```

## Visualizations

```{r, echo = FALSE}
ggplot(long_means, aes(x = Variable, y = ScaledMean, fill = Album_type)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Scaled Mean Values by Album Type",
       x = "Dependent Variables",
       y = "Scaled Mean",
       fill = "Album Type")
```

## Testing

We will test $H_0: \boldsymbol{\tau}_{album} + \boldsymbol{\tau}_{compilation} + \boldsymbol{\tau}_{single} = 0$

We couldn't use the `mancova()` function from the `jmv` package as the sample size was too large.

```{r, include = FALSE}
rm(list = ls())
set.seed(697)

df <- read_csv("C:/Users/13393/Documents/School/Senior yr/Stat 697MV/Final Project/Spotify_Youtube.csv")
```

```{r}
df <- as_tibble(df)
dependent_columns <- c(6,8:18, 22:24, 28)
df1 <- df[, dependent_columns]
df1 <- na.omit(df1)
df1 <- as_tibble(df1)

#Comparing group means with Album_type as factors
groups <- unique(df1$Album_type)
```

## Manual Code

```{r, include=FALSE}
n <- nrow(df1)
g <- length(levels(as.factor(df1$Album_type)))
p <- ncol(df1[, c(13:16)])

nms <- function(data) {
  list(
    n = nrow(data),
    m = matrix(colMeans(data), ncol = 1),
    S = cov(data)
  )
}

sum_by_type <- 
  df1[, 13:16] %>%
  split(as.factor(df1$Album_type)) %>%
  map(nms)

W <- #within-group sum of squares and cross product-matrix
  sum_by_type %>%
  map(~ (.x$n - 1) * .x$S) %>%
  reduce(`+`)

xbar <- 
  sum_by_type %>%
  map(~ .x$n * .x$m) %>%
  reduce(`+`) / n

B <- #between-group sum of squares and cross-product matrix
  sum_by_type %>%
  map(~ .x$n * (.x$m - xbar) %*% t(.x$m - xbar)) %>%
  reduce(`+`)

Wilks_Lambda <- det(W) / det(W + B)
```

```{r, echo = FALSE, out.width= "55%"}
knitr::include_graphics("manova.png")
```

